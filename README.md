# simpleChat-Streamlit

Simple chat interface to run inference on any text based Large Language Model deployed in a server over the network. 

## Steps:

- Install the requirements using requirements.txt:

    ```pip install -r requirements.txt```

- Create a `.env` file containing the URL to which the request is to be posted in a variable `URL`.
- Launch the python file using `streamlit run main.py`
- Upon launching the interface, you can give prompts for the task which the Large Language Model is trained on.

## Outputs:

![image](https://github.com/anandhu-eng/simpleChat-Streamlit/assets/71482562/29bff483-c2a3-489c-8815-1a21fae36641)

![image](https://github.com/anandhu-eng/simpleChat-Streamlit/assets/71482562/80b3718e-3e52-419f-9a17-4bbd9ba0d07f)


